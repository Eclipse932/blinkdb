
\section{Resilient Distributed Datasets (RDDs)}

A Resilient Distributed Dataset (RDD) is an immutable partitioned collection of records. An RDD can only be created through deterministic operations called \emph{transformations} on either data in stable storage or other RDDs. Examples of transformations include map, filter, and join.

RDDs do not need to be materialized at all times. Instead, each RDD contains lineage information about how it was derived from other datasets to compute its partitions from data in stable storage. This provides fault tolerance, since any RDD can be reconstructed after a failure using the lineage information. 

Users can also control the persistence and partitioning of RDDs. Users can indicate which RDDs they will reuse and choose a storage strategy for them (e.g., keeping them in memory). They can also ask that an RDD's elements be partitioned across machines based on key in each record. This is useful for placement optimizations, such as ensuring that two datasets that will be joined together are hash-partitioned in the same way.

Spark is a Scala implementation that exposes RDDs through a language-integrated API, where each dataset is represented as an object and transformations are invoked using methods on these objects. RDDs can either be defined through transformations (\eg map, filter) on data in stable storage or on other RDDs. Programmers can then use these RDDs in operations that return a value to the application or export data to stable storage. These operations, which cause the RDD to be 'computed' or materialized, are called \emph{actions} and include reduce, count, collect, and save. 

While each individual RDD itself is immutable, a mutable state abstraction can still be simulated with RDDs. A chain of RDDs can represent different versions of a dataset, with the transformations used to create each RDD analogous to changes made to mutable state. RDDs are evaluated lazily, allowing for pipelined transformations. Spark allows programmers to specify whether an RDD should be persistent and keeps persistent RDDs in memory by default, although the data can be spilled to disk if there is insufficient memory. Users can also specify persistence priorities for RDDs to control which collections are spilled to disk first.