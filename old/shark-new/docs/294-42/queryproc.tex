\section{Query Processing}

\subsection{Overview}

At a higher level, Shark's query execution consists of three steps similar to those of a traditional RDBMS: query parsing, logical plan generation, and physical plan generation. Hive provides a SQL-like declarative query language, HiveQL, which supports standard operators including select, project, join, aggregate, union, and from clauses with sub-queries. HiveQL statements are compiled into lower level operators, which, in Hive, are executed as a sequence of MapReduce programs. Shark uses Hive as a third-party Java library for query parsing and logical plan generation. The main difference is in the physical plan execution, as Shark has its own operators written specifically to exploit the benefits provided by RDDs.

Given a HiveQL query, the Hive query compiler parses the query and generates an abstract syntax tree. The tree is then turned into the logical plan and basic logical optimization such as predicate pushdown is applied. Shark uses the existing Hive code for each of these steps. In Hive, this operator tree would then be converted into a physical plan that consisted of subtrees for separate map and reduce tasks. 

In Shark, the operator tree is executed with operators that perform transformations on RDDs. An iterator traverses the operator tree and produces an immutable RDD for each operator on the tree. The initial RDD for any query over a table is created by the table scan operator and consists of a collection of the rows in the table. Subsequent operators create new RDDs by applying map, filter, join, and other transformations. Unlike Hive, which applies its operators to tables one row at a time and writes intermediate data between MapReduce jobs to disk, in Shark, an RDD produced by an operator is not materialized until the execution engine returns the query results. At this time, the contents of the final RDD are computed by applying the appropriate transformations to the RDDs of previous operators.

Much of the common structure of Hive operators is retained in order to ensure interoperability with HiveQL. Shark currently supports all of the essential Hive operators. We reuse all of Hive's data model and type system, in addition to supporting Hive's user-defined functions, user-defined aggregate functions, custom types, and custom serialization/deserialization methods.

While the transformations available in Spark were sufficient to express most Hive operators, we had to modify Spark to implement sorting on RDDs for 'order by' clauses and to implement full outer joins. 
% any other modifications to spark?

\subsection{Caching}

A major advantage of Shark over Hive lies in its inter-query caching of data. The Spark framework provides a simple mechanism to cache RDDs in memory across clusters and recompute RDDs in the event of failures. In Shark, the resulting RDD generated by each operator subtree can be cached automatically, and a signature is computed for the subtree. This signature and a reference to the associated RDD is stored in an in-memory hash table. Signatures are computed for subsequent query subtrees and are compared to those in the table and, in the case of a match, the in-memory RDD is utilized. 

Cache invalidation is handled by checking the timestamp of the last modification of the HDFS data to the timestamp stored in our table. Spark currently supports a least recently used (LRU) policy, but we are in the process of implementing least frequently used (LFU) and are exploring more sophisticated algorithms that perform cost-based analysis for intermediate data. 

Currently, Shark automatically caches all RDDs generated by operators. Users can prevent the RDDs generated by certain operators via a global configuration file. This helps avoid filling available memory with, for example, the RDDs created by table scans on large tables, when subsequent queries perform similar filtering to narrow down the result set.

%\subsection{Implementation Details}
%The Shark code base consists of approximately 2300 lines of Scala code. The Shark driver replaces the Hive 
% driver and controls query plan execution,

% reducesink and the way we avoid writing intermediate data 
% shuffles and advantages of hash joins 
% various optimizations like kryo serialization

% Maybe mention:
% ¥ challenges, esp. those of integrating Hive with Spark;
% - serdes 
% - gc issues
%  - how we did it orginally, what happened, how we fixed it using lazy serialization
% - challenges that this presents for caching
% mention recent modifications to spark

% talk about explicit memory management in hive vs. spark and what problems this seems to pose


