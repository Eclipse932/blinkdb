SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_1024_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100122_366715227.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0042, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0042
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0042
2012-04-10 01:22:46,465 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:22:58,727 Stage-1 map = 19%,  reduce = 0%
2012-04-10 01:23:01,771 Stage-1 map = 50%,  reduce = 0%
2012-04-10 01:23:11,073 Stage-1 map = 75%,  reduce = 0%
2012-04-10 01:23:14,086 Stage-1 map = 81%,  reduce = 17%
2012-04-10 01:23:17,100 Stage-1 map = 100%,  reduce = 17%
2012-04-10 01:23:23,125 Stage-1 map = 100%,  reduce = 25%
2012-04-10 01:23:26,138 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0042
OK
890169.6953811646
Time taken: 60.143 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_1024_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100123_1132199350.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0043, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0043
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0043
2012-04-10 01:23:44,480 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:23:52,875 Stage-1 map = 67%,  reduce = 0%
2012-04-10 01:24:01,963 Stage-1 map = 100%,  reduce = 22%
2012-04-10 01:24:08,072 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0043
OK
890169.6953811646
Time taken: 40.035 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_1024_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100124_869052215.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0044, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0044
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0044
2012-04-10 01:24:26,301 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:24:32,364 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:24:41,446 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0044
OK
890169.6953811646
Time taken: 31.389 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_512_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100124_1306636836.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0045, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0045
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0045
2012-04-10 01:24:59,608 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:25:11,976 Stage-1 map = 75%,  reduce = 0%
2012-04-10 01:25:15,018 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:25:21,110 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0045
OK
828016.6499595642
Time taken: 36.884 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_512_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100125_1077299944.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0046, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0046
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0046
2012-04-10 01:25:38,458 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:25:47,910 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:25:56,980 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0046
OK
828016.6499595642
Time taken: 35.092 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_512_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100126_1173547468.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0047, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0047
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0047
2012-04-10 01:26:14,449 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:26:20,548 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:26:29,617 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0047
OK
828016.6499595642
Time taken: 30.704 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_256_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100126_1794005382.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0048, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0048
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0048
2012-04-10 01:26:47,985 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:26:57,070 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:27:06,165 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0048
OK
785450.4053878784
Time taken: 34.55 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_256_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100127_1187898962.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0049, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0049
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0049
2012-04-10 01:27:24,261 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:27:30,365 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:27:39,568 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0049
OK
785450.4053878784
Time taken: 31.421 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_256_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100127_2027956417.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0050, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0050
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0050
2012-04-10 01:27:57,993 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:28:04,036 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:28:13,098 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0050
OK
785450.4053878784
Time taken: 31.685 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_128_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100128_438234442.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0051, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0051
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0051
2012-04-10 01:28:31,324 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:28:40,561 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:28:49,627 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0051
OK
824666.0260467529
Time taken: 34.655 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_128_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100128_1583546475.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0052, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0052
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0052
2012-04-10 01:29:07,469 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:29:13,559 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:29:22,645 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0052
OK
824666.0260467529
Time taken: 31.321 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_128_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100129_1274159018.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0053, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0053
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0053
2012-04-10 01:29:40,719 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:29:46,901 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:29:56,001 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0053
OK
824666.0260467529
Time taken: 31.547 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_64_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100130_551589982.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0054, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0054
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0054
2012-04-10 01:30:13,341 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:30:19,493 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:30:28,603 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0054
OK
865028.0352783203
Time taken: 30.805 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_64_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100130_1828042706.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0055, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0055
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0055
2012-04-10 01:30:46,922 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:30:53,104 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:31:02,284 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0055
OK
865028.0352783203
Time taken: 31.87 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_64_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100131_373071085.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0056, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0056
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0056
2012-04-10 01:31:20,320 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:31:26,419 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:31:35,484 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0056
OK
865028.0352783203
Time taken: 31.377 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_32_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100131_1593198562.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0057, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0057
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0057
2012-04-10 01:31:53,666 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:31:59,721 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:32:08,780 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0057
OK
892914.4487915039
Time taken: 31.52 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_32_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100132_1674264304.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0058, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0058
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0058
2012-04-10 01:32:26,264 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:32:32,304 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:32:41,360 Stage-1 map = 100%,  reduce = 33%
2012-04-10 01:32:44,425 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0058
OK
892914.4487915039
Time taken: 33.832 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_32_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100132_1469256310.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0059, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0059
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0059
2012-04-10 01:33:02,681 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:33:08,797 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:33:17,875 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0059
OK
892914.4487915039
Time taken: 31.623 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_16_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100133_651509898.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0060, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0060
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0060
2012-04-10 01:33:36,119 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:33:42,200 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:33:51,293 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0060
OK
852555.1025390625
Time taken: 31.588 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_16_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100133_1019206253.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0061, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0061
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0061
2012-04-10 01:34:12,368 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:34:18,401 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:34:27,475 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0061
OK
852555.1025390625
Time taken: 34.361 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_16_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100134_202949636.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0062, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0062
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0062
2012-04-10 01:34:45,772 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:34:51,865 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:35:00,933 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0062
OK
852555.1025390625
Time taken: 31.533 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_8_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100135_1709267871.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0063, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0063
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0063
2012-04-10 01:35:22,036 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:35:28,077 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:35:37,138 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0063
OK
772145.2758789062
Time taken: 34.152 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_8_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100135_612467496.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0064, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0064
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0064
2012-04-10 01:35:55,180 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:36:00,351 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:36:09,415 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0064
OK
772145.2758789062
Time taken: 30.3 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_8_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100136_21351835.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0065, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0065
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0065
2012-04-10 01:36:28,365 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:36:34,405 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:36:43,556 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0065
OK
772145.2758789062
Time taken: 32.413 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_4_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100136_574011438.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0066, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0066
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0066
2012-04-10 01:37:01,161 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:37:07,282 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:37:16,444 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0066
OK
742675.40625
Time taken: 30.976 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_4_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100137_366320988.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0067, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0067
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0067
2012-04-10 01:37:34,925 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:37:41,008 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:37:50,069 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0067
OK
742675.40625
Time taken: 31.78 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_4_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100137_1224291904.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0068, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0068
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0068
2012-04-10 01:38:07,335 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:38:13,409 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:38:22,484 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0068
OK
742675.40625
Time taken: 30.618 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_2_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100138_963569328.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0069, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0069
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0069
2012-04-10 01:38:44,109 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:38:50,215 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:38:59,331 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0069
OK
726411.9453125
Time taken: 34.828 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_2_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100139_1186259680.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0070, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0070
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0070
2012-04-10 01:39:16,946 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:39:23,077 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:39:32,167 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0070
OK
726411.9453125
Time taken: 30.914 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_2_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100139_13185835.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0071, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0071
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0071
2012-04-10 01:39:52,902 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:39:58,948 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:40:08,000 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0071
OK
726411.9453125
Time taken: 33.986 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_sample_1_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100140_191835877.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0072, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0072
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0072
2012-04-10 01:40:29,894 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:40:32,977 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:40:42,035 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0072
OK
698665.568359375
Time taken: 32.039 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_sample_1_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100140_249791708.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0073, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0073
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0073
2012-04-10 01:41:00,255 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:41:06,326 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:41:15,418 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0073
OK
698665.568359375
Time taken: 31.379 seconds
SELECT avg(sessiontimems) FROM anon_sdm2_ss_rc_compressed_sample_1_mb;
Hive history file=/tmp/ubuntu/hive_job_log_ubuntu_201204100141_1781710654.txt
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapred.reduce.tasks=<number>
Starting Job = job_201204080125_0074, Tracking URL = http://localhost:50030/jobdetails.jsp?jobid=job_201204080125_0074
Kill Command = /mnt/data/hive-cdh/src/build/hadoopcore/hadoop-0.20.1/bin/../bin/hadoop job  -Dmapred.job.tracker=localhost:54311 -kill job_201204080125_0074
2012-04-10 01:41:36,609 Stage-1 map = 0%,  reduce = 0%
2012-04-10 01:41:41,779 Stage-1 map = 100%,  reduce = 0%
2012-04-10 01:41:51,018 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_201204080125_0074
OK
698665.568359375
Time taken: 33.773 seconds
